{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d88cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note this is a simple implementation from this source: \n",
    "# https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de619b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"../images/barack_obama.jpg\")\n",
    "obama_face_encoding =  face_recognition.face_encodings(obama_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"../images/joe_biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "jerico_image = face_recognition.load_image_file(\"../images/jerico_johns.jpg\")\n",
    "jerico_face_encoding = face_recognition.face_encodings(jerico_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "sudhrity_image = face_recognition.load_image_file(\"../images/sudhrity_mondal.jpg\")\n",
    "sudhrity_face_encoding = face_recognition.face_encodings(sudhrity_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "diana_image = face_recognition.load_image_file(\"../images/diana_chacon.jpg\")\n",
    "diana_face_encoding = face_recognition.face_encodings(diana_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "josh_image = face_recognition.load_image_file(\"../images/josh_jonte.jpg\")\n",
    "josh_face_encoding = face_recognition.face_encodings(josh_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "piotr_image = face_recognition.load_image_file(\"../images/piotr_parkitny.jpg\")\n",
    "piotr_face_encoding = face_recognition.face_encodings(piotr_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "kevin_image = face_recognition.load_image_file(\"../images/kevin_martin.jpg\")\n",
    "kevin_face_encoding = face_recognition.face_encodings(kevin_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "eric_image = face_recognition.load_image_file(\"../images/eric_lundy.jpg\")\n",
    "eric_face_encoding = face_recognition.face_encodings(eric_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "divesh_image = face_recognition.load_image_file(\"../images/divesh_kumar.jpg\")\n",
    "divesh_face_encoding = face_recognition.face_encodings(divesh_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "catherine_image = face_recognition.load_image_file(\"../images/catherine_mou.jpg\")\n",
    "catherine_face_encoding = face_recognition.face_encodings(catherine_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "brad_image = face_recognition.load_image_file(\"../images/brad_desaulniers.jpg\")\n",
    "brad_face_encoding = face_recognition.face_encodings(brad_image)[0]\n",
    "# Load another sample picture and learn how to recognize it.\n",
    "alice_image = face_recognition.load_image_file(\"../images/alice_hua.jpg\")\n",
    "alice_face_encoding = face_recognition.face_encodings(alice_image)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f584d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding,\n",
    "    jerico_face_encoding,\n",
    "    sudhrity_face_encoding,\n",
    "    diana_face_encoding,\n",
    "    josh_face_encoding,\n",
    "    piotr_face_encoding,\n",
    "    kevin_face_encoding,\n",
    "    eric_face_encoding,\n",
    "    divesh_face_encoding,\n",
    "    catherine_face_encoding,\n",
    "    brad_face_encoding,\n",
    "    alice_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\",\n",
    "    \"Jerico Johns\",\n",
    "    \"Sudhrity Mondal\",\n",
    "    \"Diana Chacon\",\n",
    "    \"Josh Jonte\",\n",
    "    \"Piotr Parkkitny\",\n",
    "    \"Kevin Martin\",\n",
    "    \"Eric Lundy\",\n",
    "    \"Divesh Kumar\",\n",
    "    \"Catherine Mou\",\n",
    "    \"Brad Desaulniers\",\n",
    "    \"Alice Hua\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93918785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotion recognition\n",
    "def load_trained_model(model_path):\n",
    "    model = Face_Emotion_CNN()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage), strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_trained_model('../models/emotion_m1.pt')\n",
    "emotion_dict = {0: 'Neutral', 1: 'Happy', 2: 'Surprise', 3: 'Sad',\n",
    "                    4: 'Angry'}\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969a5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision-0.8.0a0+45f960c-py3.6-linux-aarch64.egg/torchvision/transforms/functional.py:92: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /media/nvidia/WD_NVME/PyTorch/JetPack_4.4.1/pytorch-v1.7.0/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    #process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "        #resize_frame = cv2.resize(gray[y:y + h, x:x + w], (48, 48))\n",
    "        resize_frame = cv2.resize(gray[top:bottom, left:right], (48, 48))\n",
    "\n",
    "        X = resize_frame/256\n",
    "        X = Image.fromarray((X))\n",
    "        X = val_transform(X).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            log_ps = model.cpu()(X)\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            pred = emotion_dict[int(top_class.numpy())] \n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 100, 0), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        #cv2.rectangle(frame, (left+2, bottom - 50), (right-2, bottom-26), (152, 251, 152), cv2.FILLED)\n",
    "        #font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        x, y, w, h = left+2, bottom-50, right-2, bottom-26\n",
    "        sub_img = frame[y:h, x:w]\n",
    "        white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 255\n",
    "        res = cv2.addWeighted(sub_img, 0.8, white_rect, 0.1, 1.0)\n",
    "        frame[y:h, x:w] = res\n",
    "\n",
    "        scale = 0.05 # this value can be from 0 to 1 (0,1] to change the size of the text relative to the image\n",
    "        fontScale = min(w,h)/(25/scale)\n",
    "\n",
    "        #cv2.putText(frame, name, (left + 6, bottom - 29), font, 1.0, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 29), font, fontScale, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        #cv2.rectangle(frame, (left+2, bottom - 25), (right-2, bottom-2), (47, 79, 79), cv2.FILLED)\n",
    "        #font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #cv2.putText(frame, pred, (left + 6, bottom - 4), font, 1.0, (34, 139, 34), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        # First we crop the sub-rect from the image\n",
    "        x, y, w, h = left+2, bottom-25, right-2, bottom-2\n",
    "        #sub_img = frame[y:y+h, x:x+w]\n",
    "        sub_img = frame[y:h, x:w]\n",
    "        white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 255\n",
    "        res = cv2.addWeighted(sub_img, 0.6, white_rect, 0.2, 1.0)\n",
    "\n",
    "        # Putting the image back to its position\n",
    "        #frame[y:y+h, x:x+w] = res\n",
    "        frame[y:h, x:w] = res\n",
    "        #cv2.putText(frame, pred, (left + 6, bottom - 4), font, fontScale, (34, 139, 34), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, pred, (left + 6, bottom - 4), font, fontScale, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        ##  Draw a label with a name below the face\n",
    "        #cv2.rectangle(frame, (left+2, bottom - 35), (right-2, byttom-2), (152, 251, 152), cv2.FILLED)\n",
    "        #font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (34, 139, 34), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20002c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36630339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8b8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
